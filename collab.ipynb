{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaleido\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib.util\n",
    "import argparse\n",
    "import shutil\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ----------------------------------------\n",
    "# Module: utils\n",
    "# ----------------------------------------\n",
    "def install_requirements(modules_string):\n",
    "    modules = modules_string.split()\n",
    "    for module in modules:\n",
    "        if importlib.util.find_spec(module) is None:\n",
    "            try:\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", module])\n",
    "                print(f\"Successfully installed {module}.\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"An error occurred while installing {module}: {e}\")\n",
    "                sys.exit(1)\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Stock Analysis Script\")\n",
    "    parser.add_argument('ticker', type=str, help='Stock ticker symbol (e.g., AAPL)')\n",
    "    parser.add_argument('start_date', type=str, help='Start date for stock data (format: YYYY-MM-DD)')\n",
    "    parser.add_argument('end_date', type=str, help='End date for stock data (format: YYYY-MM-DD)')\n",
    "    return parser.parse_args()\n",
    "\n",
    "# ----------------------------------------\n",
    "# Module: data\n",
    "# ----------------------------------------\n",
    "def load_data(ticker, start_date, end_date):\n",
    "    df = pd.DataFrame(ticker.history(start=start_date, end=end_date))\n",
    "    df.index = pd.to_datetime(df.index.strftime(r'%Y/%m/%d'))\n",
    "    return df\n",
    "\n",
    "def data_split(df):\n",
    "    df_prices = df[['Close','Volume']]\n",
    "    if 'Stock Splits' in df.columns:\n",
    "        df_actions = df[['Dividends', 'Stock Splits','Close']]\n",
    "    else:\n",
    "        df_actions = df[['Dividends', 'Close']]\n",
    "    return df_prices, df_actions\n",
    "\n",
    "def fill_data(df):\n",
    "    df.index = pd.to_datetime(df.index.strftime(r'%Y/%m/%d'))\n",
    "    df = df.reset_index().rename(columns={'index': 'Date'})\n",
    "    full_date_range = pd.date_range(start=df['Date'].min(), end=df['Date'].max(), freq='D')\n",
    "    df = df.set_index('Date').reindex(full_date_range)\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].interpolate()\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------\n",
    "# Module: visualizations\n",
    "# ----------------------------------------\n",
    "def plot_df_prices(df):\n",
    "    fig_prices = go.Figure()\n",
    "    fig_vol = go.Figure()\n",
    "    fig_prices.add_trace(go.Scatter(x=df.index, y=df['Close'], mode='lines', name='Close'))\n",
    "    fig_vol.add_trace(go.Scatter(x=df.index, y=df['Volume'], mode='lines', name='Volume'))\n",
    "    return fig_prices, fig_vol\n",
    "\n",
    "def volatility(df):\n",
    "    df['Daily_Return'] = df['Close'].pct_change()\n",
    "    df['Volatility_30'] = df['Daily_Return'].rolling(window=30).std()\n",
    "    df['Volatility_90'] = df['Daily_Return'].rolling(window=90).std()\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df['Volatility_30'], mode='lines', name='30-Day Volatility', line=dict(color='blue')))\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df['Volatility_90'], mode='lines', name='90-Day Volatility', line=dict(color='red')))\n",
    "    fig.update_layout(title='Stock Volatility Over Time', xaxis_title='Date', yaxis_title='Volatility')\n",
    "    return fig\n",
    "\n",
    "def seasonal_decomposition_plot(df):\n",
    "    result = seasonal_decompose(df['Close'], model='additive', period=90)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=result.trend, mode='lines', name='Trend'))\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=result.seasonal, mode='lines', name='Seasonal'))\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=result.resid, mode='lines', name='Residual'))\n",
    "    fig.update_layout(title='Seasonal Decomposition of Stock Price', xaxis_title='Date', yaxis_title='Price')\n",
    "    return fig\n",
    "\n",
    "def dicky_fuller_test(df):\n",
    "    close = df['Close']\n",
    "    differenced_close = close.diff().dropna()\n",
    "    dicftest = adfuller(close)\n",
    "    diff_dicftest = adfuller(differenced_close)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=differenced_close.index, y=differenced_close.values, mode='lines', name='Differenced Close Prices'))\n",
    "    fig.update_layout(title=\"Differenced Close Prices\", xaxis_title=\"Date\", yaxis_title=\"Differenced Close Price\")\n",
    "    return dicftest, diff_dicftest, fig\n",
    "\n",
    "def plot_moving_averages(df):\n",
    "    close = df['Close']\n",
    "    ma30 = close.rolling(window=30).mean()\n",
    "    ma90 = close.rolling(window=90).mean()\n",
    "    ma120 = close.rolling(window=120).mean()\n",
    "    ma365 = close.rolling(window=365).mean()\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=ma30, mode='lines', name='30-Day MA'))\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=ma90, mode='lines', name='90-Day MA'))\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=ma120, mode='lines', name='120-Day MA'))\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=ma365, mode='lines', name='365-Day MA'))\n",
    "    fig.update_layout(title='Moving Averages of Close Price', xaxis_title='Date', yaxis_title='Price')\n",
    "    return fig\n",
    "\n",
    "def dividend_yield_plot(df):\n",
    "    df['Yield'] = df['Dividends'] / df['Close']\n",
    "    df_filtered = df[df['Dividends'] != 0]\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df_filtered.index, y=df_filtered['Yield'], mode='markers', name='Yield'))\n",
    "    fig.update_layout(title='Dividend Yield Over Time', xaxis_title='Date', yaxis_title='Yield', template='plotly_dark')\n",
    "    return fig\n",
    "\n",
    "# ----------------------------------------\n",
    "# Module: dlmodels\n",
    "# ----------------------------------------\n",
    "def dl_output(df):\n",
    "    def metric_funcs(actual, pred):\n",
    "        def MAPE(actual, pred):\n",
    "            return mean_absolute_percentage_error(actual, pred)\n",
    "        def R2(actual, pred):\n",
    "            return r2_score(actual, pred)\n",
    "        def MAE(actual, pred):\n",
    "            return mean_absolute_error(actual, pred)\n",
    "        def RMSE(actual, pred):\n",
    "            return np.sqrt(mean_squared_error(actual, pred))\n",
    "        return MAPE, R2, MAE, RMSE\n",
    "\n",
    "    data = df.filter(['Close'])\n",
    "    dataset = data.values\n",
    "    training_data_len = int(np.ceil(len(dataset) * 0.90))\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "    train_data = scaled_data[:training_data_len, :]\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(90, len(train_data)):\n",
    "        x_train.append(train_data[i-90:i, 0])\n",
    "        y_train.append(train_data[i, 0])\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "\n",
    "    def rnn_model(model_type):\n",
    "        model = Sequential()\n",
    "        if model_type == 'GRU':\n",
    "            model.add(GRU(128, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "            model.add(GRU(64, return_sequences=False))\n",
    "        elif model_type == 'LSTM':\n",
    "            model.add(LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "            model.add(LSTM(64, return_sequences=False))\n",
    "        model.add(Dense(25))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        model.fit(x_train, y_train, batch_size=1, epochs=1, verbose=0)\n",
    "\n",
    "        test_data = scaled_data[training_data_len - 90:]\n",
    "        x_test = []\n",
    "        y_test = dataset[training_data_len:]\n",
    "        for i in range(90, len(test_data)):\n",
    "            x_test.append(test_data[i-90:i, 0])\n",
    "        x_test = np.array(x_test).reshape(len(x_test), 90, 1)\n",
    "        predictions = model.predict(x_test)\n",
    "        predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "        MAPE, R2, MAE, RMSE = metric_funcs(y_test, predictions)\n",
    "        metrics = {\n",
    "            'RMSE': RMSE(y_test, predictions),\n",
    "            'MAPE': MAPE(y_test, predictions),\n",
    "            'MAE': MAE(y_test, predictions),\n",
    "            'R2': R2(y_test, predictions)\n",
    "        }\n",
    "\n",
    "        train = data[:training_data_len]\n",
    "        valid = data[training_data_len:].copy()\n",
    "        valid['Predictions'] = predictions\n",
    "        trace_train = go.Scatter(x=train.index, y=train['Close'], mode='lines', name='Train', line=dict(color='blue'))\n",
    "        trace_valid = go.Scatter(x=valid.index, y=valid['Close'], mode='lines', name='Actual', line=dict(color='blue'))\n",
    "        trace_pred = go.Scatter(x=valid.index, y=valid['Predictions'], mode='lines', name='Predicted', line=dict(color='red', dash='dash'))\n",
    "        fig = go.Figure(data=[trace_train, trace_valid, trace_pred])\n",
    "        fig.update_layout(title=f'{model_type} Model Predictions', xaxis_title='Date', yaxis_title='Close Price')\n",
    "        return metrics, fig, predictions, y_test\n",
    "\n",
    "    return {\n",
    "        'LSTM': rnn_model('LSTM'),\n",
    "        'GRU': rnn_model('GRU')\n",
    "    }\n",
    "\n",
    "# ----------------------------------------\n",
    "# Module: evaluation\n",
    "# ----------------------------------------\n",
    "def calculate_residuals(actual, predicted):\n",
    "    residuals = actual - predicted\n",
    "    return residuals\n",
    "\n",
    "def plot_residuals(residuals):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=residuals, nbinsx=50))\n",
    "    fig.update_layout(\n",
    "        title=\"Residuals Histogram\",\n",
    "        xaxis_title=\"Residual\",\n",
    "        yaxis_title=\"Count\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def theils_u(actual, predicted):\n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    naive_forecast = np.roll(actual, 1)\n",
    "    naive_forecast[0] = actual[0]\n",
    "    mse_model = np.mean((predicted - actual)**2)\n",
    "    mse_naive = np.mean((naive_forecast - actual)**2)\n",
    "    u = np.sqrt(mse_model / mse_naive)\n",
    "    return u\n",
    "\n",
    "def plot_visual_comparison(actual, predicted):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(len(actual)),\n",
    "        y=actual,\n",
    "        mode='lines',\n",
    "        name='Actual',\n",
    "        line=dict(color='blue')\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(len(predicted)),\n",
    "        y=predicted,\n",
    "        mode='lines',\n",
    "        name='Predicted',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=\"Visual Comparison: Actual vs. Predicted\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Value\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def time_series_cross_validation(model_func, series, initial_train_size, forecast_horizon, step_size):\n",
    "    n = len(series)\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    for start in range(initial_train_size, n - forecast_horizon + 1, step_size):\n",
    "        train = series[:start]\n",
    "        test = series[start:start + forecast_horizon]\n",
    "        forecast = model_func(train, forecast_horizon)\n",
    "        predictions.extend(forecast)\n",
    "        actuals.extend(test)\n",
    "    return np.array(actuals), np.array(predictions)\n",
    "\n",
    "def backtesting_forecast(model_func, series, forecast_horizon, rolling_window):\n",
    "    n = len(series)\n",
    "    predictions = []\n",
    "    forecast_times = []\n",
    "    for start in range(0, n - forecast_horizon, rolling_window):\n",
    "        train = series[:start + forecast_horizon]\n",
    "        forecast = model_func(train, forecast_horizon)\n",
    "        predictions.append(forecast[0])  # Assuming forecast_horizon=1 for simplicity\n",
    "        forecast_times.append(start + forecast_horizon)\n",
    "    predictions = np.array(predictions)\n",
    "    actual = series[forecast_times]\n",
    "    return forecast_times, actual, predictions\n",
    "\n",
    "def naive_forecast(train, forecast_horizon):\n",
    "    last_value = train[-1]\n",
    "    return [last_value] * forecast_horizon\n",
    "\n",
    "# ----------------------------------------\n",
    "# Helper: save figure with fallback\n",
    "# ----------------------------------------\n",
    "def save_figure(fig, png_path, html_path):\n",
    "    try:\n",
    "        fig.write_image(png_path)\n",
    "        return png_path  # Return PNG path if successful\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {png_path} using kaleido: {e}\\nFalling back to HTML export.\")\n",
    "        fig.write_html(html_path)\n",
    "        return html_path  # Return HTML path as fallback\n",
    "\n",
    "# ----------------------------------------\n",
    "# Main code\n",
    "# ----------------------------------------\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    is_collab = True\n",
    "except ImportError:\n",
    "    is_collab = False\n",
    "\n",
    "def main():\n",
    "    # Ensure required packages are installed (kaleido, plotly, etc.)\n",
    "    install_requirements(\"yfinance pandas numpy plotly statsmodels scikit-learn keras kaleido\")\n",
    "    \n",
    "    # For Colab testing, use default parameters if no command-line arguments are provided.\n",
    "    if len(sys.argv) < 4:\n",
    "        ticker_symbol = \"AAPL\"\n",
    "        start_date = \"2020-01-01\"\n",
    "        end_date = \"2021-01-01\"\n",
    "        print(\"No command-line arguments provided. Using default ticker AAPL and date range 2020-01-01 to 2021-01-01\")\n",
    "    else:\n",
    "        args = parse_args()\n",
    "        ticker_symbol, start_date, end_date = args.ticker, args.start_date, args.end_date\n",
    "\n",
    "    ticker = yf.Ticker(ticker_symbol.upper())\n",
    "    full_df = load_data(ticker, start_date, end_date)\n",
    "    df_prices, df_actions = data_split(full_df)\n",
    "    df_filled = fill_data(df_prices)\n",
    "\n",
    "    fig_prices, fig_volume = plot_df_prices(df_filled)\n",
    "    vol_fig = volatility(df_filled)\n",
    "    season_fig = seasonal_decomposition_plot(df_filled)\n",
    "    dicky_results = dicky_fuller_test(df_filled)\n",
    "    dicky_fig = dicky_results[2]\n",
    "    ma_fig = plot_moving_averages(df_filled)\n",
    "    dy_fig = dividend_yield_plot(df_actions)\n",
    "\n",
    "    dl_results = dl_output(df_filled)\n",
    "    lstm_metrics, lstm_fig, lstm_predictions, actual_values = dl_results['LSTM']\n",
    "    gru_metrics, gru_fig, gru_predictions, _ = dl_results['GRU']\n",
    "\n",
    "    u_stat = theils_u(actual_values, lstm_predictions)\n",
    "\n",
    "    series = df_filled['Close'].values.flatten()\n",
    "    initial_train_size = int(0.7 * len(series))\n",
    "    forecast_horizon = 1\n",
    "    step_size = 10\n",
    "    actual_cv, predictions_cv = time_series_cross_validation(naive_forecast, series, initial_train_size, forecast_horizon, step_size)\n",
    "    cv_fig = plot_visual_comparison(actual_cv, predictions_cv)\n",
    "    cv_fig.update_layout(title=\"Naive Forecast Cross-Validation\")\n",
    "    \n",
    "    rolling_window = 10\n",
    "    forecast_times, actual_bt, predictions_bt = backtesting_forecast(naive_forecast, series, forecast_horizon, rolling_window)\n",
    "    bt_fig = plot_visual_comparison(actual_bt, predictions_bt)\n",
    "    bt_fig.update_layout(title=\"Naive Forecast Backtesting\")\n",
    "\n",
    "    # Create directory for saving plots\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "    # Save figures using the helper function (PNG if possible, otherwise HTML)\n",
    "    paths = {}\n",
    "    paths['prices'] = save_figure(fig_prices, \"plots/prices.png\", \"plots/prices.html\")\n",
    "    paths['volume'] = save_figure(fig_volume, \"plots/volume.png\", \"plots/volume.html\")\n",
    "    paths['volatility'] = save_figure(vol_fig, \"plots/volatility.png\", \"plots/volatility.html\")\n",
    "    paths['seasonal'] = save_figure(season_fig, \"plots/seasonal_decomposition.png\", \"plots/seasonal_decomposition.html\")\n",
    "    paths['dickey'] = save_figure(dicky_fig, \"plots/dickey_fuller.png\", \"plots/dickey_fuller.html\")\n",
    "    paths['moving_avg'] = save_figure(ma_fig, \"plots/moving_averages.png\", \"plots/moving_averages.html\")\n",
    "    paths['dividend'] = save_figure(dy_fig, \"plots/dividend_yield.png\", \"plots/dividend_yield.html\")\n",
    "    paths['lstm'] = save_figure(lstm_fig, \"plots/lstm_predictions.png\", \"plots/lstm_predictions.html\")\n",
    "    paths['gru'] = save_figure(gru_fig, \"plots/gru_predictions.png\", \"plots/gru_predictions.html\")\n",
    "    paths['cv'] = save_figure(cv_fig, \"plots/cross_validation.png\", \"plots/cross_validation.html\")\n",
    "    paths['bt'] = save_figure(bt_fig, \"plots/backtesting.png\", \"plots/backtesting.html\")\n",
    "\n",
    "    report_lines = []\n",
    "\n",
    "    # 1. Title and Introduction\n",
    "    report_lines.append(f\"# Stock Analysis Report: {ticker_symbol.upper()}\")\n",
    "    report_lines.append(\"\")\n",
    "    report_lines.append(\"## 1. Introduction and Overview\")\n",
    "    report_lines.append(f\"This report presents an analysis of stock data for the ticker symbol **{ticker_symbol.upper()}** from **{start_date}** to **{end_date}**. \"\n",
    "                        \"It covers data loading, visualization, deep learning forecasts, and forecast evaluation metrics.\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "    # 2. Detailed Definitions and Explanations\n",
    "    report_lines.append(\"## 2. Definitions and Explanations\")\n",
    "    report_lines.append(\"### 2.1 Basic Stock Metrics\")\n",
    "    report_lines.append(\"- **Close Price**: The final trading price of the stock for the day. This value is critical for gauging market sentiment at the end of trading sessions.\")\n",
    "    report_lines.append(\"- **Volume**: The total number of shares traded during a given period. High volume often signals increased market interest or volatility.\")\n",
    "    report_lines.append(\"\")\n",
    "    report_lines.append(\"### 2.2 Time Series and Statistical Analysis\")\n",
    "    report_lines.append(\"- **Volatility**: A measure of how much the stock price fluctuates over time, calculated over intervals such as 30-day and 90-day periods.\")\n",
    "    report_lines.append(\"- **Seasonal Decomposition**: A process that splits a time series into trend, seasonal, and residual components to better understand underlying patterns.\")\n",
    "    report_lines.append(\"- **Dickey-Fuller Test**: A statistical test used to determine if a time series is stationary, which is a necessary condition for many forecasting models.\")\n",
    "    report_lines.append(\"\")\n",
    "    report_lines.append(\"### 2.3 Technical Indicators\")\n",
    "    report_lines.append(\"- **Moving Averages**: Techniques that smooth out short-term fluctuations to reveal longer-term trends. Common periods include 30, 90, 120, and 365 days.\")\n",
    "    report_lines.append(\"- **Dividend Yield**: The ratio of a companyâ€™s annual dividend relative to its share price, used to assess the income potential of an investment.\")\n",
    "    report_lines.append(\"\")\n",
    "    report_lines.append(\"### 2.4 Forecasting Models and Evaluation Metrics\")\n",
    "    report_lines.append(\"- **LSTM (Long Short-Term Memory)**: A type of recurrent neural network that captures long-term dependencies, used here to forecast closing prices.\")\n",
    "    report_lines.append(\"- **GRU (Gated Recurrent Unit)**: A streamlined version of LSTM with fewer parameters, offering similar forecasting capabilities with improved computational efficiency.\")\n",
    "    report_lines.append(\"- **Theil's U Statistic**: A metric that compares the performance of the forecast model to a naive forecast. Lower values indicate better performance.\")\n",
    "    report_lines.append(\"- **Naive Forecast**: A baseline forecasting method that simply carries forward the last observed value as the future prediction.\")\n",
    "    report_lines.append(\"- **Cross-Validation**: A method to assess model generalizability by partitioning data into training and validation sets.\")\n",
    "    report_lines.append(\"- **Backtesting**: The process of evaluating a forecasting model using historical data to simulate its performance in real-world scenarios.\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "    # 3. Data Loading and Preparation\n",
    "    report_lines.append(\"## 3. Data Loading and Preparation\")\n",
    "    report_lines.append(f\"The dataset was obtained from Yahoo Finance for the ticker symbol **{ticker_symbol.upper()}** between **{start_date}** and **{end_date}**. \"\n",
    "                        \"Missing values were filled using interpolation to create a continuous time series for analysis.\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "    # 4. Visualizations and Detailed Results\n",
    "    report_lines.append(\"## 4. Visualizations and Detailed Results\")\n",
    "    report_lines.append(\"\")\n",
    "    # 4.1 Stock Prices\n",
    "    report_lines.append(\"### 4.1 Stock Prices\")\n",
    "    report_lines.append(\"**Description**: This plot displays the daily closing prices over the analysis period.\")\n",
    "    report_lines.append(\"**Interpretation**: Fluctuations in the closing price indicate overall market trends, investor sentiment, and potential support/resistance levels.\")\n",
    "    report_lines.append(\"![Stock Prices](plots/prices.png)\")\n",
    "    report_lines.append(\"\")\n",
    "    # 4.2 Trading Volume\n",
    "    report_lines.append(\"### 4.2 Trading Volume\")\n",
    "    report_lines.append(\"**Description**: This chart shows the volume of shares traded each day.\")\n",
    "    report_lines.append(\"**Interpretation**: High trading volume may signal increased market interest or impending price movements.\")\n",
    "    report_lines.append(\"![Trading Volume](plots/volume.png)\")\n",
    "    report_lines.append(\"\")\n",
    "    # 4.3 Volatility\n",
    "    report_lines.append(\"### 4.3 Volatility\")\n",
    "    report_lines.append(\"**Description**: This visualization illustrates the stock's volatility over 30-day and 90-day intervals.\")\n",
    "    report_lines.append(\"**Interpretation**: Volatility is a key risk metric; higher volatility implies greater uncertainty and risk.\")\n",
    "    report_lines.append(\"![Volatility](plots/volatility.png)\")\n",
    "    report_lines.append(\"\")\n",
    "    # 4.4 Seasonal Decomposition\n",
    "    report_lines.append(\"### 4.4 Seasonal Decomposition\")\n",
    "    report_lines.append(\"**Description**: The seasonal decomposition plot breaks the stock price data into trend, seasonal, and residual components.\")\n",
    "    report_lines.append(\"**Interpretation**: This helps identify underlying patterns, cyclical behavior, and irregular fluctuations.\")\n",
    "    report_lines.append(\"![Seasonal Decomposition](plots/seasonal_decomposition.png)\")\n",
    "    report_lines.append(\"\")\n",
    "    # 4.5 Dickey-Fuller Test\n",
    "    report_lines.append(\"### 4.5 Dickey-Fuller Test (Differenced Close Prices)\")\n",
    "    report_lines.append(\"**Description**: This plot shows the differenced close prices used for assessing the stationarity of the time series.\")\n",
    "    report_lines.append(\"**Interpretation**: A stationary time series is crucial for reliable forecasting; the Dickey-Fuller test helps determine stationarity.\")\n",
    "    report_lines.append(\"![Dickey-Fuller Test](plots/dickey_fuller.png)\")\n",
    "    report_lines.append(\"\")\n",
    "    # 4.6 Moving Averages\n",
    "    report_lines.append(\"### 4.6 Moving Averages\")\n",
    "    report_lines.append(\"**Description**: This plot overlays several moving averages (30, 90, 120, and 365 days) on the closing price data.\")\n",
    "    report_lines.append(\"**Interpretation**: Moving averages smooth out short-term fluctuations, clarifying the overall trend in stock prices.\")\n",
    "    report_lines.append(\"![Moving Averages](plots/moving_averages.png)\")\n",
    "    report_lines.append(\"\")\n",
    "    # 4.7 Dividend Yield\n",
    "    report_lines.append(\"### 4.7 Dividend Yield\")\n",
    "    report_lines.append(\"**Description**: This visualization displays the dividend yield over time.\")\n",
    "    report_lines.append(\"**Interpretation**: Dividend yield is an important metric for income-focused investors, indicating the cash return on investment relative to the stock price.\")\n",
    "    report_lines.append(\"![Dividend Yield](plots/dividend_yield.png)\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "    # 5. Deep Learning Model Forecasts\n",
    "    report_lines.append(\"## 5. Deep Learning Model Forecasts\")\n",
    "    report_lines.append(\"The deep learning models (LSTM and GRU) were trained on 90% of the data to forecast the stock's closing price.\")\n",
    "    report_lines.append(\"\")\n",
    "    # 5.1 LSTM Model\n",
    "    report_lines.append(\"### 5.1 LSTM Model Forecast\")\n",
    "    report_lines.append(\"**Metrics:**\")\n",
    "    for key, value in lstm_metrics.items():\n",
    "        report_lines.append(f\"- **{key}**: {value:.4f}\")\n",
    "    report_lines.append(\"**Visualization:** The plot below compares the LSTM model's predictions to the actual stock prices.\")\n",
    "    report_lines.append(\"![LSTM Predictions](plots/lstm_predictions.png)\")\n",
    "    report_lines.append(\"\")\n",
    "    # 5.2 GRU Model\n",
    "    report_lines.append(\"### 5.2 GRU Model Forecast\")\n",
    "    report_lines.append(\"**Metrics:**\")\n",
    "    for key, value in gru_metrics.items():\n",
    "        report_lines.append(f\"- **{key}**: {value:.4f}\")\n",
    "    report_lines.append(\"**Visualization:** The plot below shows the GRU model's predictions alongside the actual values.\")\n",
    "    report_lines.append(\"![GRU Predictions](plots/gru_predictions.png)\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "    # 6. Forecast Evaluation\n",
    "    report_lines.append(\"## 6. Forecast Evaluation\")\n",
    "    # 6.1 Theil's U Statistic\n",
    "    report_lines.append(\"### 6.1 Theil's U Statistic\")\n",
    "    report_lines.append(f\"- **Theil's U**: {u_stat:.4f}\")\n",
    "    report_lines.append(\"**Interpretation:** A lower Theil's U value indicates that the forecasting model performs better than the naive forecast.\")\n",
    "    report_lines.append(\"\")\n",
    "    # 6.2 Cross-Validation\n",
    "    report_lines.append(\"### 6.2 Cross-Validation (Naive Forecast)\")\n",
    "    report_lines.append(\"**Description:** This plot shows the results of cross-validation using a naive forecasting approach.\")\n",
    "    report_lines.append(\"**Interpretation:** Cross-validation assesses the consistency of the naive forecast across different data segments.\")\n",
    "    report_lines.append(\"![Cross-Validation](plots/cross_validation.png)\")\n",
    "    report_lines.append(\"\")\n",
    "    # 6.3 Backtesting Forecast\n",
    "    report_lines.append(\"### 6.3 Backtesting Forecast (Naive Forecast)\")\n",
    "    report_lines.append(\"**Description:** The backtesting chart evaluates forecast performance using a rolling window on historical data.\")\n",
    "    report_lines.append(\"**Interpretation:** Backtesting helps verify that the forecast model's performance is robust over time.\")\n",
    "    report_lines.append(\"![Backtesting Forecast](plots/backtesting.png)\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "    # 7. Conclusion\n",
    "    report_lines.append(\"## 7. Conclusion\")\n",
    "    report_lines.append(\"This report summarizes the key findings from the stock analysis. The detailed visualizations reveal important trends and patterns in the stock's performance, while the deep learning models offer forecasts benchmarked against naive methods. \"\n",
    "                        \"The comprehensive definitions and explanations provided throughout this report are intended to assist in interpreting the analysis results and making informed investment decisions.\")\n",
    "\n",
    "    report_content = \"\\n\".join(report_lines)\n",
    "\n",
    "    with open(\"report.md\", \"w\") as f:\n",
    "        f.write(report_content)\n",
    "\n",
    "    print(\"Markdown report generated as report.md.\")\n",
    "\n",
    "    shutil.make_archive(\"plots\", 'zip', \"plots\")\n",
    "    print(\"Created plots.zip containing the image files.\")\n",
    "\n",
    "    if is_collab:\n",
    "        from google.colab import files\n",
    "        files.download(\"report.md\")\n",
    "        files.download(\"plots.zip\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
